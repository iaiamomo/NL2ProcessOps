## Code generation evaluation
Evaluated over a set of 10 textual process description with relative manual generated Python function implementations ([data](data)).

### Results
$CodeBLEU=\alpha \cdot BLEU+\beta \cdot BLEU_{weight} + \gamma \cdot Match_{ast} + \delta \cdot Match_{df}$ \
$BLEU=$ n-grams comparison between the candidate and the reference, and calculates the ratio of matched n-grams\
$BLEU_{weight}=$ weighted n-grams match \
$Match_{ast}=$ syntactic AST match \
$Match_{df}=$ semantic data flow match

CodeBLEU weights `(0.1, 0.1, 0.4, 0.4)`

#### With pre-processing
```
  model process  codebleu      bleu  bleu_weight  match_ast  match_df
0  gpt4     p01  0.615587  0.092619     0.220428   0.682927  0.777778
1  gpt4     p02  0.642729  0.110080     0.390381   0.731707  0.750000
2  gpt4     p03  0.666706  0.152358     0.369595   0.782178  0.754098
3  gpt4     p04  0.499240  0.065907     0.168916   0.666667  0.522727
4  gpt4     p05  0.554111  0.071697     0.292378   0.657895  0.636364
5  gpt4     p06  0.634138  0.192621     0.489258   0.718447  0.696429
6  gpt4     p07  0.663023  0.027232     0.179518   0.716981  0.888889
7  gpt4     p08  0.621741  0.036436     0.213236   0.750000  0.741935
8  gpt4     p09  0.555611  0.025797     0.112877   0.693069  0.661290
9  gpt4     p10  0.545400  0.074508     0.142743   0.697248  0.611940
```
```
codebleu: 0.599829
bleu: 0.084926
bleu_weight: 0.257933
match_ast: 0.709712
match_df: 0.704145
```

#### With pre-processing + distinct models
```
  model process  codebleu      bleu  bleu_weight  match_ast  match_df
0   gpt     p01  0.575303  0.062619     0.243257   0.695122  0.666667
1   gpt     p02  0.640607  0.088858     0.390381   0.731707  0.750000
2   gpt     p03  0.567528  0.110967     0.326205   0.702970  0.606557
3   gpt     p04  0.493993  0.093954     0.142818   0.653061  0.522727
4   gpt     p05  0.635913  0.084091     0.313316   0.763158  0.727273
5   gpt     p06  0.656912  0.147374     0.360025   0.747573  0.767857
6   gpt     p07  0.599217  0.043038     0.271982   0.641509  0.777778
7   gpt     p08  0.646450  0.131576     0.466915   0.692308  0.774194
8   gpt     p09  0.582092  0.025035     0.055865   0.693069  0.741935
9   gpt     p10  0.404258  0.042872     0.144302   0.486239  0.477612
```
```
codebleu: 0.580227
bleu: 0.083038
bleu_weight: 0.271507
match_ast: 0.680672
match_df: 0.68126
```

#### Without pre-processing
```
  model process  codebleu      bleu  bleu_weight  match_ast  match_df
0  gpt4     p01  0.602823  0.043435     0.141977   0.682927  0.777778
1  gpt4     p02  0.640913  0.090497     0.391808   0.731707  0.750000
2  gpt4     p03  0.592535  0.118780     0.359404   0.673267  0.688525
3  gpt4     p04  0.447896  0.054815     0.138741   0.605442  0.465909
4  gpt4     p05  0.633462  0.062865     0.386591   0.789474  0.681818
5  gpt4     p06  0.669550  0.164875     0.436311   0.737864  0.785714
6  gpt4     p07  0.606985  0.030139     0.171791   0.716981  0.750000
7  gpt4     p08  0.608932  0.040898     0.209710   0.750000  0.709677
8  gpt4     p09  0.580049  0.023196     0.101786   0.693069  0.725806
9  gpt4     p10  0.581737  0.052884     0.142139   0.733945  0.671642
```
```
codebleu: 0.596488
bleu: 0.068238
bleu_weight: 0.248026
match_ast: 0.711468
match_df: 0.700687
```

#### Without pre-processing + distinct models
```
  model process  codebleu      bleu  bleu_weight  match_ast  match_df
0   gpt     p01  0.653721  0.077962     0.212095   0.695122  0.866667
1   gpt     p02  0.637889  0.060248     0.391808   0.731707  0.750000
2   gpt     p03  0.592803  0.121457     0.359404   0.673267  0.688525
3   gpt     p04  0.477062  0.080131     0.160183   0.666667  0.465909
4   gpt     p05  0.675889  0.037829     0.290435   0.789474  0.818182
5   gpt     p06  0.635736  0.122692     0.315804   0.747573  0.732143
6   gpt     p07  0.567463  0.033799     0.185901   0.641509  0.722222
7   gpt     p08  0.597957  0.038412     0.229003   0.653846  0.774194
8   gpt     p09  0.635222  0.041703     0.154022   0.732673  0.806452
9   gpt     p10  0.492508  0.049732     0.143042   0.541284  0.641791
```
```
codebleu: 0.596625
bleu: 0.066397
bleu_weight: 0.24417
match_ast: 0.687312
match_df: 0.726608
```

#### Without process model
```
  model process  codebleu      bleu  bleu_weight  match_ast  match_df
0  gpt4     p01  0.462752  0.045344     0.112798   0.695122  0.422222
1  gpt4     p02  0.533857  0.084772     0.390381   0.365854  0.850000
2  gpt4     p03  0.511196  0.133175     0.293828   0.613861  0.557377
3  gpt4     p04  0.420938  0.063819     0.133192   0.639456  0.363636
4  gpt4     p05  0.587681  0.045706     0.290435   0.657895  0.727273
5  gpt4     p06  0.601184  0.226039     0.418253   0.699029  0.642857
6  gpt4     p07  0.657550  0.045253     0.173849   0.811321  0.777778
7  gpt4     p08  0.708927  0.036545     0.209050   0.807692  0.903226
8  gpt4     p09  0.498521  0.012271     0.039688   0.475248  0.758065
9  gpt4     p10  0.392787  0.049140     0.138345   0.532110  0.402985
```
```
codebleu: 0.537539
bleu: 0.074206
bleu_weight: 0.219982
match_ast: 0.629759
match_df: 0.640542
```

#### Copilot
```
     model process  codebleu      bleu  bleu_weight  match_ast  match_df
0  copilot     p01  0.408391  0.109266     0.179527   0.548780  0.400000
1  copilot     p02  0.279168  0.035970     0.082540   0.268293  0.400000
2  copilot     p03  0.272242  0.028794     0.047955   0.366337  0.295082
3  copilot     p04  0.444315  0.056221     0.074312   0.612245  0.465909
4  copilot     p05  0.425849  0.130979     0.318897   0.315789  0.636364
5  copilot     p06  0.369029  0.028167     0.052550   0.563107  0.339286
6  copilot     p07  0.382015  0.002500     0.010526   0.396226  0.555556
7  copilot     p08  0.344252  0.032626     0.064977   0.384615  0.451613
8  copilot     p09  0.488768  0.009509     0.016461   0.683168  0.532258
9  copilot     p10  0.351872  0.049003     0.129174   0.596330  0.238806
```
```
codebleu: 0.37659
bleu: 0.048303
bleu_weight: 0.097692
match_ast: 0.473489
match_df: 0.431487
```